
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>MICCAI 2024 Challenge on Long-tailed, multi-label, and zero-shot classification on chest X-rays</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
</head>

<body>

<div class="container">
  <table border="0" align="center">
    <tr>
      <td width="800" align="center" valign="middle"><h3>MICCAI 2024 Challenge</h3>
      <span class="title">CXR-LT: Long-tailed, multi-label, and zero-shot classification on chest X-rays</span></td>
    </tr>
    <tr>
    <h2><td colspan="3" align="center"><br> 
      Location: Marrakesh, Morocco<br>
      Time: <b>TBD, October 2024</b>
    </td>
    </h2>
    </tr>
  </table>
<!--   <p><img src="figures/teaser.jpg" width="1000" align="middle" /></p> -->
</div>

<br>

<div class="containersmall">
  <center><b>Click here to participate in Task 1: INSERT LINK</b></center>
  <center><b>Click here to participate in Task 2: INSERT LINK</b></center>
  <center><b>Click here to participate in Task 3: INSERT LINK</b></center>
</div>

<br>


<div class="container">
  <h2>Overview</h2>
  <div class="overview">
    <p><span><span>Chest radiography, like many diagnostic medical exams, produces a <strong>long-tailed</strong> distribution of clinical findings; while a small subset of diseases is routinely observed, the vast majority of diseases are relatively rare [1]. This poses a challenge for standard deep learning methods, which exhibit bias toward the most common classes at the expense of the important but rare &ldquo;tail&rdquo classes [2]. Many existing methods [3] have been proposed to tackle this specific type of imbalance, though only recently has attention been given to long-tailed medical image recognition problems [4-6]. Diagnosis on chest X-rays (CXRs) is also a <strong>multi-label</strong> problem, as patients often present with multiple disease findings simultaneously; however, only a select few studies incorporate knowledge of label co-occurrence into the learning process [7-9, 12]. Since most large-scale image classification benchmarks contain single-label images with a mostly balanced distribution of labels, many standard deep learning methods fail to accommodate the class imbalance and co-occurrence problems posed by the long-tailed, multi-label nature of tasks like disease diagnosis on CXRs [2].</span></span></p>

    <p><span><span>In the first iteration of CXR-LT held in 2023, we expanded upon the <a href="https://physionet.org/content/mimic-cxr-jpg/2.0.0/">MIMIC-CXR-JPG</a> [10,11] dataset by enlarging the set of target classes from 14 to 26, generating labels for 12 new rare disease findings by parsing radiology reports [13]. While this made for a challenging long-tailed, multi-label disease classification task that attracted 59 teams who contributed over 500 unique submissions, Radiology Gamuts Ontology documents over 4,500 unique radiological image findings. That is, the  &ldquo;true&rdquo distribution of all clinical findings on CXR is at least two orders of magnitude longer than what our -- or any existing dataset can offer. For this reason, we argue that the only way to truly tackle the long-tail of radiological image findings is to develop a model that can readily generalize to new classes in &ldquo;zero-shot&rdquo fashion [14].</span></span></p>

    <p><span><span>For this year's version of CXR-LT, we extract labels for an additional 19 rare disease findings (for a total of 377,110 CXR images, each with 45 disease labels) and introduce two new challenge tracks, featuring a zero-shot classification task. We additionally include N=200 images from the Medical Imaging and Data Resource Center (MIDRC) (<a href="https://data.midrc.org/"></a>) for additional evaluation in the second task. </span></span></p>  </div>
</div>

<br>

<div class="container">
  <h2>Shared Task</h2>
    <div class="overview">
      <h3> Dataset </h3>
      <p>In the first iteration of CXR-LT held in 2023, we expanded upon the MIMIC-CXR dataset by enlarging the set of target classes from 14 to 26, generating labels for 12 new rare disease findings by parsing radiology reports. For this year's version of CXR-LT, we extract labels for an additional 19 rare disease findings (for a total of 377,110 CXR images, each with 45 disease labels).</p>

      <h3>Task</h3>
      <p>Given a CXR, detect all pathologies present (or predict “No Finding” if none present). To do this, you will train multi-label thorax disease classifiers on the provided labeled training data.</p>

      <h3>Evaluation</h3>
      <p>Models will be evaluated on the provided testing set using “macro-averaged” mean Average Precision (mAP).
      </p>

      <h3>Online Evaluation</h3>
      <p>The competition will be conducted through the <a href="https://codalab.lisn.upsaclay.fr/">CodaLab</a> platform.
      </p>
    </div>
</div>

<br>

<div class="container">
  <h2>Tentative Schedule</h2>
    <div class="schedule">
      <p class="subtitle"><span class="announce_date">5/1/2024</span>. Training data released and challenge (development phase) begins</p>
      <p class="subtitle"><span class="announce_date">8/1/2024</span>. Test labels released and final evaluation (test phase) begins</p>
      <p class="subtitle"><span class="announce_date">8/4/2024</span>. Test phase ends and competition is closed.</p>
      <p class="subtitle"><span class="announce_date">8/15/2024</span>. Top-performing teams invited to present at MICCAI 2024</p>
      <p class="subtitle"><span class="announce_date">10/6/2024 or 10/10/2024</span>. MICCAI 2024 CXR-LT Challenge event</p>
    </div>
</div>

<br>

<div class="containersmall">
  <h2>Steering committee</h2>
    <div class="instructor">
    <a href="https://www.hsph.harvard.edu/ecpe/faculty/leo-anthony-celi/">
      <div class="instructorphoto"><img src="figures/Leo.png"></div>
      <div>Leo Anthony Celi<br>MIT/Harvard<br></div>
    </a>
  </div>
  <div class="instructor">
    <a href="https://www.ncbi.nlm.nih.gov/research/bionlp/Zhiyong-Lu">
      <div class="instructorphoto"><img src="figures/zhiyong_lu.png"></div>
      <div>Zhiyong Lu<br>NIH/NLM/NCBI<br></div>
    </a>
  </div>
  <div class="instructor">
    <a href="https://vivo.weill.cornell.edu/display/cwid-ges9006">
      <div class="instructorphoto"><img src="figures/george_shih.jpg"></div>
      <div>George Shih<br>Weill Cornell Medicine<br></div>
    </a>
  </div>
  <div class="instructor">
    <a href="https://irp.nih.gov/pi/ronald-summers">
      <div class="instructorphoto"><img src="figures/rsummers.jpg"></div>
      <div>Ronald M. Summers<br>NIH Clinical Center<br></div>
    </a>
  </div>
  <div class="instructor">
    <a href="https://irp.nih.gov/pi/ronald-summers">
      <div class="instructorphoto"><img src="figures/adam_flanders.jpg"></div>
      <div>Adam E. Flanders<br>Thomas Jefferson University<br></div>
    </a>
  </div>
</div>

<br>

<div class="containersmall">
  <h2>Organizers</h2>
  
  <div class="instructor">
    <a href="https://penglab.weill.cornell.edu/">
      <div class="instructorphoto"><img src="figures/yifan_peng.jpg"></div>
      <div>Yifan Peng<br>Weill Cornell Medicine<br></div>
    </a>
  </div>

  <div class="instructor">
    <a href="">
      <div class="instructorphoto"><img src="figures/MINGQUAN_LIN.jpg"></div>
      <div>Mingquan Lin<br>Weill Cornell Medicine<br></div>
    </a>
  </div>

  <div class="instructor">
    <a href="">
      <div class="instructorphoto"><img src="figures/greg_holste.jpg"></div>
      <div>Greg Holste<br>UT Austin<br></div>
    </a>
  </div>

  <div class="instructor">
    <a href="">
      <div class="instructorphoto"><img src="figures/song_wang.jpg"></div>
      <div>Song Wang<br>UT Austin<br></div>
    </a>
  </div>

  <div class="instructor">
    <a href="">
      <div class="instructorphoto"><img src="figures/yiliang_zhou.jpeg"></div>
      <div>Yiliang Zhou<br>Weill Cornell Medicine<br></div>
    </a>
  </div>

  <div class="instructor">
    <a href="">
      <div class="instructorphoto"><img src="figures/hao_chen.jpg"></div>
      <div>Hao Chen<br>HKUST<br></div>
    </a>
  </div>

  <div class="instructor">
    <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang#:~:text=Professor%20Zhangyang%20%E2%80%9CAtlas%E2%80%9D%20Wang%20is,University%20of%20Texas%20at%20Austin.">
      <div class="instructorphoto"><img src="figures/atlas_wang.jpg"></div>
      <div>Atlas Wang<br>UT at Austin<br></div>
    </a>
  </div>
</div>

<br>

<div class="container">
  <h2>References</h2>
    <div class="overview">
      <ol>
        <li>Zhou SK, Greenspan H, Davatzikos C, Duncan JS, Van Ginneken B, Madabhushi A, Prince JL, Rueckert D, Summers RM. A review of deep learning in medical imaging: Imaging traits, technology trends, case studies with progress highlights, and future promises. Proceedings of the IEEE. 2021 Feb 26;109(5):820-38.</li>
        <li>Holste G, Wang S, Jiang Z, Shen TC, Shih G, Summers RM, Peng Y, Wang Z. Long-Tailed Classification of Thorax Diseases on Chest X-Ray: A New Benchmark Study. In Data Augmentation, Labelling, and Imperfections: Second MICCAI Workshop, DALI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 22, 2022, Proceedings 2022 Sep 16 (pp. 22-32). Cham: Springer Nature Switzerland.</li>
        <li>Zhang Y, Kang B, Hooi B, Yan S, Feng J. Deep long-tailed learning: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence. 2023 Apr 19.</li>
        <li>Zhang R, Haihong E, Yuan L, He J, Zhang H, Zhang S, Wang Y, Song M, Wang L. MBNM: multi-branch network based on memory features for long-tailed medical image recognition. Computer Methods and Programs in Biomedicine. 2021 Nov 1;212:106448.</li>
        <li>Ju L, Wang X, Wang L, Liu T, Zhao X, Drummond T, Mahapatra D, Ge Z. Relational subsets knowledge distillation for long-tailed retinal diseases recognition. In Medical Image Computing and Computer Assisted Intervention&ndash;MICCAI 2021: 24th International Conference, Strasbourg, France, September 27&ndash;October 1, 2021, Proceedings, Part VIII 24 2021 (pp. 3-12). Springer International Publishing.</li>
        <li>Yang Z, Pan J, Yang Y, Shi X, Zhou HY, Zhang Z, Bian C. ProCo: Prototype-Aware Contrastive Learning for Long-Tailed Medical Image Classification. In Medical Image Computing and Computer Assisted Intervention&ndash;MICCAI 2022: 25th International Conference, Singapore, September 18&ndash;22, 2022, Proceedings, Part VIII 2022 Sep 16 (pp. 173-182). Cham: Springer Nature Switzerland.</li>
        <li>Chen H, Miao S, Xu D, Hager GD, Harrison AP. Deep hierarchical multi-label classification of chest X-ray images. In International Conference on Medical Imaging with Deep Learning 2019 May 24 (pp. 109-120). PMLR.</li>
        <li>Wang G, Wang P, Cong J, Liu K, Wei B. BB-GCN: A Bi-modal Bridged Graph Convolutional Network for Multi-label Chest X-Ray Recognition. arXiv preprint arXiv:2302.11082. 2023 Feb 22.</li>
        <li>Chen B, Li J, Lu G, Yu H, Zhang D. Label co-occurrence learning with graph convolutional networks for multi-label chest x-ray image classification. IEEE Journal of Biomedical and Health Informatics. 2020 Jan 16;24(8):2292-302.</li>
        <li>Johnson AE, Pollard TJ, Greenbaum NR, Lungren MP, Deng CY, Peng Y, Lu Z, Mark RG, Berkowitz SJ, Horng S. MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs. arXiv preprint arXiv:1901.07042. 2019 Jan 21.</li>
        <li>Moukheiber D, Mahindre S, Moukheiber L, Moukheiber M, Wang S, Ma C, Shih G, Peng Y, Gao M. Few-Shot Learning Geometric Ensemble for Multi-label Classification of Chest X-Rays. In Data Augmentation, Labelling, and Imperfections: Second MICCAI Workshop, DALI 2022, Held in Conjunction with MICCAI 2022, Singapore, September 22, 2022, Proceedings 2022 Sep 16 (pp. 112-122). Cham: Springer Nature Switzerland.</li>
      </ol>    </div>
</div>

<br>

<div class="containersmall">
    <p>Please contact <a href="mailto:cxrltchallenge2024@gmail.com">cxrltchallenge2024@gmail.com</a> if you have any questions. This webpage template is by courtesy of <a href="https://gkioxari.github.io/">Georgia</a>.</p>
    <p>This comeptition is sponsored in part by the Artifical Intelligence Journal (AIJ).</p>
    <center><img src="https://aij.ijcai.org/wp-content/uploads/2021/07/ARTINT_Logo2_c_web_more.jpg" width="10%"></img></center>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>

